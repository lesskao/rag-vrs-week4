"""
RAG ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
"""
import sys
import os

# è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.vectorstores import ChromaVectorStore
from src.rag_engine import AdvancedRAGEngine
from src.core.models import Document, QueryRequest


def example_basic_usage():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 1: åŸºç¡€ RAG ä½¿ç”¨")
    print("="*60)
    
    # 1. åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆä½¿ç”¨ Chromaï¼Œæ— éœ€é¢å¤–æœåŠ¡ï¼‰
    vector_store = ChromaVectorStore("demo_collection")
    vector_store.create_collection(dimension=768)
    
    # 2. åˆ›å»º RAG å¼•æ“
    rag_engine = AdvancedRAGEngine(vector_store)
    
    # 3. å‡†å¤‡æ–‡æ¡£
    documents = [
        Document(
            id="doc1",
            content="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚å¸¸è§çš„æ¡†æ¶åŒ…æ‹¬ TensorFlow å’Œ PyTorchã€‚",
            metadata={"category": "tech", "topic": "æ·±åº¦å­¦ä¹ "}
        ),
        Document(
            id="doc2",
            content="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›åº”ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’Œ Web å¼€å‘ã€‚å®ƒæœ‰ä¸°å¯Œçš„åº“ç”Ÿæ€ç³»ç»Ÿã€‚",
            metadata={"category": "tech", "topic": "ç¼–ç¨‹è¯­è¨€"}
        ),
        Document(
            id="doc3",
            content="å‘é‡æ•°æ®åº“æ˜¯ä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢å‘é‡æ•°æ®çš„æ•°æ®åº“ã€‚å¸¸è§çš„å‘é‡æ•°æ®åº“åŒ…æ‹¬ Milvusã€Qdrant å’Œ Chromaã€‚",
            metadata={"category": "tech", "topic": "æ•°æ®åº“"}
        )
    ]
    
    # 4. ç´¢å¼•æ–‡æ¡£
    rag_engine.index_documents(documents)
    
    # 5. æŸ¥è¯¢
    request = QueryRequest(
        query="ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
        top_k=2,
        enable_hybrid=True,
        enable_rerank=False
    )
    
    response = rag_engine.query(request, return_answer=False)
    
    print(f"\næŸ¥è¯¢ç»“æœ:")
    for i, result in enumerate(response["results"]):
        print(f"\nç»“æœ {i+1}:")
        print(f"  ID: {result.document.id}")
        print(f"  åˆ†æ•°: {result.score:.4f}")
        print(f"  å†…å®¹: {result.document.content}")
    
    # æ¸…ç†
    vector_store.drop_collection()


def example_advanced_features():
    """é«˜çº§åŠŸèƒ½ç¤ºä¾‹"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 2: é«˜çº§åŠŸèƒ½ - Multi-Query + Reranking")
    print("="*60)
    
    # 1. åˆå§‹åŒ–
    vector_store = ChromaVectorStore("advanced_demo")
    vector_store.create_collection(dimension=768)
    rag_engine = AdvancedRAGEngine(vector_store)
    
    # 2. å‡†å¤‡æ›´å¤šæ–‡æ¡£
    documents = [
        Document(
            id=f"doc{i}",
            content=content,
            metadata={"category": "tech", "index": i}
        )
        for i, content in enumerate([
            "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ã€‚",
            "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚",
            "è®¡ç®—æœºè§†è§‰ä½¿è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒä¸­è·å–ç†è§£ï¼Œåº”ç”¨åŒ…æ‹¬äººè„¸è¯†åˆ«å’Œè‡ªåŠ¨é©¾é©¶ã€‚",
            "å¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ç§ï¼Œé€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œï¼Œåœ¨å›¾åƒè¯†åˆ«å’Œè¯­éŸ³è¯†åˆ«é¢†åŸŸå–å¾—çªç ´ã€‚",
            "å¤§æ•°æ®æŠ€æœ¯ç”¨äºå¤„ç†è¶…å¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…æ‹¬ Hadoop å’Œ Sparkã€‚",
            "äº‘è®¡ç®—é€šè¿‡äº’è”ç½‘æä¾›è®¡ç®—èµ„æºï¼Œä¸»è¦æä¾›å•†åŒ…æ‹¬ AWS å’Œ Azureã€‚"
        ])
    ]
    
    rag_engine.index_documents(documents)
    
    # 3. ä½¿ç”¨é«˜çº§æŸ¥è¯¢
    request = QueryRequest(
        query="AI å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ",
        top_k=10,
        enable_hybrid=True,
        enable_rerank=True  # å¯ç”¨é‡æ’åº
    )
    
    response = rag_engine.query(request, return_answer=True)
    
    print(f"\næ£€ç´¢ç»“æœ (Top 3):")
    for i, result in enumerate(response["results"][:3]):
        print(f"\n{i+1}. [åˆ†æ•°: {result.score:.4f}]")
        print(f"   {result.document.content}")
    
    print(f"\nç”Ÿæˆçš„ç­”æ¡ˆ:")
    print(response["answer"])
    
    # æ¸…ç†
    vector_store.drop_collection()


def example_parent_child_chunking():
    """çˆ¶å­åˆ†å—ç¤ºä¾‹"""
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 3: çˆ¶å­åˆ†å—ç­–ç•¥")
    print("="*60)
    
    # 1. åˆå§‹åŒ–ï¼ˆå¯ç”¨çˆ¶å­åˆ†å—ï¼‰
    vector_store = ChromaVectorStore("parent_child_demo")
    vector_store.create_collection(dimension=768)
    rag_engine = AdvancedRAGEngine(vector_store, use_parent_child=True)
    
    # 2. å‡†å¤‡é•¿æ–‡æ¡£
    long_document = """
    äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚
    AI çš„å†å²å¯ä»¥è¿½æº¯åˆ° 20 ä¸–çºª 50 å¹´ä»£ï¼Œå½“æ—¶è‰¾ä¼¦Â·å›¾çµæå‡ºäº†è‘—åçš„"å›¾çµæµ‹è¯•"ã€‚
    
    æœºå™¨å­¦ä¹ æ˜¯ AI çš„ä¸€ä¸ªæ ¸å¿ƒå­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ è€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚
    æœºå™¨å­¦ä¹ ç®—æ³•å¯ä»¥åˆ†ä¸ºä¸‰å¤§ç±»ï¼šç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚
    ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚
    
    æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œï¼ˆä¹Ÿç§°ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œï¼‰æ¥å­¦ä¹ æ•°æ®çš„å±‚æ¬¡åŒ–è¡¨ç¤ºã€‚
    æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³è¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
    å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ç‰¹åˆ«é€‚åˆå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œè€Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œ Transformer æ¶æ„åˆ™åœ¨åºåˆ—æ•°æ®å¤„ç†ä¸­è¡¨ç°å‡ºè‰²ã€‚
    
    è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯ AI å’Œè¯­è¨€å­¦çš„äº¤å‰é¢†åŸŸï¼Œä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚
    è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å¦‚ GPTã€BERT ç­‰çš„å‡ºç°ï¼Œæå¤§åœ°æ¨åŠ¨äº† NLP é¢†åŸŸçš„å‘å±•ã€‚
    è¿™äº›æ¨¡å‹é€šè¿‡åœ¨æµ·é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œèƒ½å¤Ÿç†è§£å¤æ‚çš„è¯­è¨€æ¨¡å¼å’Œè¯­ä¹‰å…³ç³»ã€‚
    """
    
    documents = [
        Document(
            id="long_doc1",
            content=long_document,
            metadata={"category": "tech", "type": "article"}
        )
    ]
    
    # 3. ç´¢å¼•ï¼ˆä¼šè‡ªåŠ¨è¿›è¡Œçˆ¶å­åˆ†å—ï¼‰
    rag_engine.index_documents(documents)
    
    # 4. æŸ¥è¯¢ï¼ˆæ£€ç´¢åˆ°å­å—ï¼Œä½†è¿”å›çˆ¶å—ï¼‰
    request = QueryRequest(
        query="ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
        top_k=3,
        enable_hybrid=False,
        enable_rerank=False
    )
    
    response = rag_engine.query(request, return_answer=False)
    
    print(f"\næ£€ç´¢ç»“æœï¼ˆè¿”å›çˆ¶å—ä»¥æä¾›æ›´å¤šä¸Šä¸‹æ–‡ï¼‰:")
    for i, result in enumerate(response["results"][:2]):
        print(f"\nç»“æœ {i+1}:")
        print(f"  åˆ†æ•°: {result.score:.4f}")
        print(f"  å†…å®¹: {result.document.content[:200]}...")
        print(f"  æ˜¯å¦æ›¿æ¢ä¸ºçˆ¶å—: {result.document.metadata.get('replaced_with_parent', False)}")
    
    # æ¸…ç†
    vector_store.drop_collection()


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\nğŸš€ RAG ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    
    try:
        # ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨
        example_basic_usage()
        
        # ç¤ºä¾‹ 2: é«˜çº§åŠŸèƒ½ï¼ˆéœ€è¦ DeepSeek APIï¼‰
        # example_advanced_features()
        
        # ç¤ºä¾‹ 3: çˆ¶å­åˆ†å—
        # example_parent_child_chunking()
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("\nè¯·ç¡®ä¿:")
        print("  1. å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
        print("  2. å·²é…ç½® .env æ–‡ä»¶ï¼ˆå¦‚æœä½¿ç”¨ DeepSeek APIï¼‰")


if __name__ == "__main__":
    main()
